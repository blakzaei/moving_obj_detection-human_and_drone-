{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8758731,"sourceType":"datasetVersion","datasetId":5262134},{"sourceId":8779403,"sourceType":"datasetVersion","datasetId":5276935}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-- Install ultralytics for YOLO  --------------------------------------------------------------------------------\n!pip install ultralytics\n\nfrom IPython import display\ndisplay.clear_output()\n\nimport ultralytics\nultralytics.checks()\n#---------------------------------------------------------------------------------------------------------------","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-25T06:11:29.268309Z","iopub.execute_input":"2024-06-25T06:11:29.268572Z","iopub.status.idle":"2024-06-25T06:12:24.915267Z","shell.execute_reply.started":"2024-06-25T06:11:29.268549Z","shell.execute_reply":"2024-06-25T06:12:24.914265Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.2.42 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\nSetup complete âœ… (4 CPUs, 31.4 GB RAM, 5689.3/8062.4 GB disk)\n","output_type":"stream"}]},{"cell_type":"code","source":"#-- Install GroundingDINO  ----------------------------------------------------------------------------------------\n%cd /kaggle/working/  \n\n!git clone https://github.com/IDEA-Research/GroundingDINO.git\n\n%cd GroundingDINO/\n!pip install -e .\n\n!mkdir weights\n%cd weights\n!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n\n%cd /kaggle/working/GroundingDINO    \n\n#-- clear output --\nfrom IPython import display\ndisplay.clear_output()  \n\n!python -c \"import groundingdino\" && echo \"Module installed successfully\" || echo \"Module installation failed\"\n#---------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-06-25T06:12:30.089984Z","iopub.execute_input":"2024-06-25T06:12:30.090902Z","iopub.status.idle":"2024-06-25T06:13:37.885686Z","shell.execute_reply.started":"2024-06-25T06:12:30.090865Z","shell.execute_reply":"2024-06-25T06:13:37.884502Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Module installed successfully\n","output_type":"stream"}]},{"cell_type":"code","source":"#-- Import -----------------------------------------------------------------------------------------------\n%cd /kaggle/working/GroundingDINO\nfrom groundingdino.util.inference import load_model as dn_load_model\nfrom groundingdino.util.inference import load_image as dn_load_image\nfrom groundingdino.util.inference import predict as dn_predict\nfrom groundingdino.util.inference import annotate as dn_annotate\nimport groundingdino.datasets.transforms as T\n%cd /kaggle/working\n\nfrom ultralytics import YOLO\n\nimport torch\n\nimport cv2\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\n\nimport os\nimport shutil\n\nimport numpy as np\n#---------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-06-25T06:13:58.790058Z","iopub.execute_input":"2024-06-25T06:13:58.790505Z","iopub.status.idle":"2024-06-25T06:14:02.875014Z","shell.execute_reply.started":"2024-06-25T06:13:58.790469Z","shell.execute_reply":"2024-06-25T06:14:02.874057Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/GroundingDINO\n/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"#-- Initialize ---------------------------------------------------------------------------------------------------\nintput_path = '/kaggle/input/'\nout_path = '/kaggle/working/'\n\ninput_video_dir = intput_path + 'sample-videos-detecting-and-matching-objs-1/'\nresult_video_dir = out_path + 'result_videos/'\n\ndino_model_config_file = out_path + 'GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py'\ndino_model_weights_file = out_path + 'GroundingDINO/weights/groundingdino_swint_ogc.pth'\n\ndrone_detector_weights_file = intput_path + 'drone-detection-yolov8-best-weights/best.pt'\n\nDINO_BOX_THRESHOLD = 0.25\nDINO_TEXT_THRESHOLD = 0.1\n\nYOLO_CONF_THRESHOLD = 0.1\nYOLO_IOU_THRESHOLD = 0.5\n\nMOTION_THRESHOLD = 20\nIOU_THRESHOLD = 0.5\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('device:' , DEVICE)\n#---------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-06-25T08:43:46.798292Z","iopub.execute_input":"2024-06-25T08:43:46.799084Z","iopub.status.idle":"2024-06-25T08:43:46.806419Z","shell.execute_reply.started":"2024-06-25T08:43:46.799050Z","shell.execute_reply":"2024-06-25T08:43:46.805489Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"#-- Create Dir for saving Results ---------------------------------------------------------------------------------\nos.makedirs(result_video_dir, exist_ok=True)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-06-25T06:17:58.068252Z","iopub.execute_input":"2024-06-25T06:17:58.068898Z","iopub.status.idle":"2024-06-25T06:17:58.072987Z","shell.execute_reply.started":"2024-06-25T06:17:58.068867Z","shell.execute_reply":"2024-06-25T06:17:58.071987Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#-- Set labels for ZSOD Models ------------------------------------------------------------------------------------\nall_labels = ['drone', 'UAV', 'Unmanned Aerial Vehicle', 'Quadcopter']\n# all_labels = ['person']            \n\nyolo_all_labels = all_labels\n\ndino_all_labels = ''\nfor lbl in all_labels:\n    dino_all_labels += lbl + ', '\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-06-25T08:16:17.815414Z","iopub.execute_input":"2024-06-25T08:16:17.816324Z","iopub.status.idle":"2024-06-25T08:16:17.821720Z","shell.execute_reply.started":"2024-06-25T08:16:17.816287Z","shell.execute_reply":"2024-06-25T08:16:17.820734Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"#-- Create and Initialize Models ----------------------------------------------------------------------------------\n#-- YOLO World --\nmodel_yolo_world_zsod = YOLO('yolov8x-worldv2.pt')\nmodel_yolo_world_zsod.set_classes(yolo_all_labels)\n\n#-- DINO --\nmodel_dino_zsod = dn_load_model(dino_model_config_file,\n                                dino_model_weights_file,\n                                device= DEVICE)\n\n#-- Custome Model for Drone Detection --\nmodel_drone_detector_yolov8 = YOLO(drone_detector_weights_file) \n\n#-- background subtractor --\nback_sub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=100, detectShadows=False)\n\n\ndisplay.clear_output()\nprint('All models loaded successfully :)')\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-06-25T08:16:20.338665Z","iopub.execute_input":"2024-06-25T08:16:20.339528Z","iopub.status.idle":"2024-06-25T08:16:26.906696Z","shell.execute_reply.started":"2024-06-25T08:16:20.339493Z","shell.execute_reply":"2024-06-25T08:16:26.905783Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"All models loaded successfully :)\n","output_type":"stream"}]},{"cell_type":"code","source":"#-- ReCreate DINO LOAD Image for Loading image -------------------------------------------------------------------\ndef dino_load_image(input_image):\n    transform = T.Compose(\n        [\n            T.RandomResize([800], max_size=1333),\n            T.ToTensor(),\n            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ]\n    )\n    image_source = input_image.convert(\"RGB\")\n    image = np.asarray(image_source)\n    image_transformed, _ = transform(image_source, None)\n    return image, image_transformed\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-06-25T06:27:16.031960Z","iopub.execute_input":"2024-06-25T06:27:16.032424Z","iopub.status.idle":"2024-06-25T06:27:16.038641Z","shell.execute_reply.started":"2024-06-25T06:27:16.032391Z","shell.execute_reply":"2024-06-25T06:27:16.037753Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#-- calculate IOU for 2 Deteced Objects --------------------------------------------------------------------------\ndef calculate_iou(box1, box2):\n    \n    x1_1, y1_1, x2_1, y2_1 = box1\n    x1_2, y1_2, x2_2, y2_2 = box2\n    \n    x1_intersection = max(x1_1, x1_2)\n    y1_intersection = max(y1_1, y1_2)\n    x2_intersection = min(x2_1, x2_2)\n    y2_intersection = min(y2_1, y2_2)\n   \n    intersection_area = max(0, x2_intersection - x1_intersection + 1) * max(0, y2_intersection - y1_intersection + 1)    \n    box1_area = (x2_1 - x1_1 + 1) * (y2_1 - y1_1 + 1)\n    box2_area = (x2_2 - x1_2 + 1) * (y2_2 - y1_2 + 1)    \n    union_area = box1_area + box2_area - intersection_area\n    \n    iou = intersection_area / union_area\n\n    return iou\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-06-25T06:27:21.094585Z","iopub.execute_input":"2024-06-25T06:27:21.095415Z","iopub.status.idle":"2024-06-25T06:27:21.101995Z","shell.execute_reply.started":"2024-06-25T06:27:21.095385Z","shell.execute_reply":"2024-06-25T06:27:21.100983Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for video_file in os.listdir(input_video_dir):      \n    \n    if 'human' in video_file:\n        continue\n    \n\n    #-- log --\n    print(f'Processing {video_file} ==========================================================')\n    \n    #-- Create Folder for saving results --\n    dot_index = video_file.rfind('.')   \n    video_result_dir_name = 'result_for_' + video_file[:dot_index]\n    video_result_dir_path = result_video_dir + video_result_dir_name + '/'\n    os.makedirs(video_result_dir_path, exist_ok=True)\n        \n    #-- load video --\n    video_path = os.path.join(input_video_dir, video_file)    \n    video = cv2.VideoCapture(video_path)\n    \n    #-- Get number of frames and fps -- \n    number_of_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n    fps = int(video.get(cv2.CAP_PROP_FPS))\n    print(f'number_of_frames: {number_of_frames}\\nfps: {fps}')\n\n    #-- Get the width and height of the frames --\n    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    \n    #-- Initialize VideoWriter to save the output video --\n    result_video = cv2.VideoWriter(video_result_dir_path + video_file[:dot_index] + '.avi',\n                                   cv2.VideoWriter_fourcc(*'XVID'),\n                                   fps,\n                                   (frame_width, frame_height))    \n    \n    \n    #-- Run Object Detection Models Frame by Frame --\n    frame_number = 0\n    while video.isOpened():\n        ret, frame = video.read()\n        if not ret:\n            break\n        \n        main_frame = frame.copy()\n        frame_number += 1   \n        #-- log --\n        print(f'\\tProcessing frame {frame_number} ------------------------------')       \n        \n        \n        #-- Apply background subtraction --\n        fg_mask = back_sub.apply(frame)        \n        \n        #-- show some frames --\n        if frame_number % (number_of_frames//5) == 0:\n            plt.figure(figsize=(5, 5))\n            plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n            plt.axis('off')\n            plt.title(f'main frame - frame number={frame_number}')\n            file_name = f'main_frame_{frame_number}.png'\n            plt.savefig(video_result_dir_path + file_name)\n            plt.show()\n\n            plt.figure(figsize=(5, 5))\n            plt.imshow(cv2.cvtColor(fg_mask, cv2.COLOR_BGR2RGB))\n            plt.axis('off')\n            plt.title(f'fg_mask - frame number={frame_number}')\n            file_name = f'fg_mask_{frame_number}.png'\n            plt.savefig(video_result_dir_path + file_name)\n            plt.show()\n        \n        #-- Detect objects by YOLO-World --\n        results_yolo_world_zsod = model_yolo_world_zsod.predict(source=frame,\n                                                                conf=YOLO_CONF_THRESHOLD,\n                                                                iou=YOLO_IOU_THRESHOLD,\n                                                                show=False,\n                                                                save=False)\n        \n        \n        #-- Detect objects by DINO --\n        pil_image = Image.fromarray(frame)           \n        image_source, image = dino_load_image(pil_image)\n        boxes, logits, phrases = dn_predict(model = model_dino_zsod,\n                                            image = image,\n                                            caption = dino_all_labels,\n                                            box_threshold = DINO_BOX_THRESHOLD,\n                                            text_threshold = DINO_TEXT_THRESHOLD)   \n        \n        \n        #-- Detect Drones by trained YOLO-v8 model --\n        results_yolov8_drone = model_drone_detector_yolov8.predict(source=frame,\n                                                                   conf=YOLO_CONF_THRESHOLD,\n                                                                   iou=YOLO_IOU_THRESHOLD,\n                                                                   show=False,\n                                                                   save=False)\n        \n        \n        #-- Get only moving objects from results_yolo_world_zsod --\n        moving_objects_yolo_world_zsod = []        \n        for result in results_yolo_world_zsod:\n            for box in result.boxes:  \n                class_id = int(box.cls)                 \n                label = yolo_all_labels[class_id]    \n                bbox = box.xyxy.tolist()[0]            \n                x1, y1, x2, y2 = map(int, bbox)                \n\n                #-- Check if the detected object has motion --\n                if fg_mask[y1:y2, x1:x2].mean() > MOTION_THRESHOLD:  \n                    moving_objects_yolo_world_zsod.append((x1, y1, x2, y2, label))  \n        \n        #-- Get only moving objects from results_yolov8_drone --\n        moving_objects_yolov8_drone = []        \n        for result in results_yolov8_drone:\n            for box in result.boxes:  \n                class_id = int(box.cls) \n                label = yolo_all_labels[class_id]    \n                bbox = box.xyxy.tolist()[0]            \n                x1, y1, x2, y2 = map(int, bbox)                \n\n                #-- Check if the detected object has motion --\n                if fg_mask[y1:y2, x1:x2].mean() > MOTION_THRESHOLD:  \n                    moving_objects_yolov8_drone.append((x1, y1, x2, y2, label))  \n        \n        \n        #-- Get only moving objects from results_dino --\n        moving_objects_dino_zsod = []\n        for bbox, phrase in zip(boxes, phrases):        \n            label = phrase \n            center_x, center_y, width, height = bbox.tolist()\n            \n            #-- convert bbox to x1,y1,x2,y2 (un-normal) --\n            center_x_abs = center_x * frame_width\n            center_y_abs = center_y * frame_height\n            width_abs = width * frame_width\n            height_abs = height * frame_height            \n            x1 = int(center_x_abs - (width_abs / 2))\n            y1 = int(center_y_abs - (height_abs / 2))\n            x2 = int(center_x_abs + (width_abs / 2))\n            y2 = int(center_y_abs + (height_abs / 2)) \n            \n            #-- Check if the detected object has motion --\n            if fg_mask[y1:y2, x1:x2].mean() > MOTION_THRESHOLD:  \n                moving_objects_dino_zsod.append((x1, y1, x2, y2, label))  \n            \n        \n        #-- log --\n        print(f'yolov8:{len(moving_objects_yolov8_drone)}\\nyolo_world:{len(moving_objects_yolo_world_zsod)}\\ndino:{len(moving_objects_dino_zsod)}')\n        \n        #-- Get union of moving objects --\n        moving_objects = []        \n        matched_indices_yolo_world = set()\n        matched_indices_dino = set()\n        \n        \n        for drone_obj in moving_objects_yolov8_drone:\n            drone_box = drone_obj[0:4]\n            drone_lbl = 'drone' + '_yolov8'         \n\n            merged = False            \n\n            for i, yolo_obj in enumerate(moving_objects_yolo_world_zsod):\n                if i in matched_indices_yolo_world:\n                    continue  \n                    \n                yolo_box =  yolo_obj[0:4]  \n                \n                iou = calculate_iou(drone_box, yolo_box)\n                if iou >= IOU_THRESHOLD and not merged:\n                    merged_box_corners = [\n                        min(drone_box[0], yolo_box[0]),  # x1\n                        min(drone_box[1], yolo_box[1]),  # y1\n                        max(drone_box[2], yolo_box[2]),  # x2\n                        max(drone_box[3], yolo_box[3])]   # y2\n\n                    moving_objects.append((merged_box_corners[0],\n                                           merged_box_corners[1],\n                                           merged_box_corners[2],\n                                           merged_box_corners[3],\n                                           drone_lbl))                        \n\n                    matched_indices_yolo_world.add(i)\n                    merged = True\n                    #break\n                \n                elif iou >= IOU_THRESHOLD and merged:\n                    matched_indices_yolo_world.add(i)\n                \n                \n            for i, dino_obj in enumerate(moving_objects_dino_zsod):\n                if i in matched_indices_dino:\n                    continue  \n\n                dino_box =  dino_obj[0:4]  \n\n                iou = calculate_iou(drone_box, dino_box)\n                if iou >= IOU_THRESHOLD and not merged:\n                    merged_box_corners = [\n                        min(drone_box[0], dino_box[0]),  # x1\n                        min(drone_box[1], dino_box[1]),  # y1\n                        max(drone_box[2], dino_box[2]),  # x2\n                        max(drone_box[3], dino_box[3])]   # y2\n\n                    moving_objects.append((merged_box_corners[0],\n                                               merged_box_corners[1],\n                                               merged_box_corners[2],\n                                               merged_box_corners[3],\n                                               drone_lbl))                        \n\n                    matched_indices_dino.add(i)\n                    merged = True\n                    #break   \n                    \n                elif iou >= IOU_THRESHOLD and merged:\n                    matched_indices_dino.add(i)\n                    \n            \n            if not merged:  \n                moving_objects.append((drone_box[0],\n                                       drone_box[1],\n                                       drone_box[2],\n                                       drone_box[3],\n                                       drone_lbl))    \n                    \n#                 moving_objects.append(drone_obj)\n        \n\n        for j, yolo_obj in enumerate(moving_objects_yolo_world_zsod):\n            if j in matched_indices_yolo_world:\n                    continue \n       \n            yolo_box = yolo_obj[0:4]\n            yolo_lbl = yolo_obj[-1]+ '_yolo_world'        \n\n            merged = False            \n\n            for i, dino_obj in enumerate(moving_objects_dino_zsod):\n                if i in matched_indices_dino:\n                    continue  \n                    \n                dino_box =  dino_obj[0:4]  \n                \n                iou = calculate_iou(yolo_box, dino_box)\n                if iou >= IOU_THRESHOLD and not merged:\n                    merged_box_corners = [\n                        min(yolo_box[0], dino_box[0]),  # x1\n                        min(yolo_box[1], dino_box[1]),  # y1\n                        max(yolo_box[2], dino_box[2]),  # x2\n                        max(yolo_box[3], dino_box[3])]   # y2\n\n                    moving_objects.append((merged_box_corners[0],\n                                           merged_box_corners[1],\n                                           merged_box_corners[2],\n                                           merged_box_corners[3],\n                                           yolo_lbl))                        \n\n                    matched_indices_dino.add(i)\n                    merged = True\n                    #break\n                elif iou >= IOU_THRESHOLD and merged:\n                    matched_indices_dino.add(i)\n                \n            if not merged:     \n                moving_objects.append((yolo_box[0],\n                                       yolo_box[1],\n                                       yolo_box[2],\n                                       yolo_box[3],\n                                       yolo_lbl)) \n                #moving_objects.append(yolo_obj)\n\n        #-- Add remaining boxes from dino_objects that were not matched --\n        for i, dino_obj in enumerate(moving_objects_dino_zsod):\n            if i not in matched_indices_dino:\n                dino_box = dino_obj[0:4]\n                dino_lbl = dino_obj[-1]+ '_dino'  \n                moving_objects.append((dino_box[0],\n                                       dino_box[1],\n                                       dino_box[2],\n                                       dino_box[3],\n                                       dino_lbl)) \n#                 moving_objects.append(dino_obj)        \n\n\n        #-- plot bounding box for moving objects on the frame --\n        for i, (x1, y1, x2, y2, label) in enumerate(moving_objects):            \n            #-- crop detected object --\n            cropped_object = main_frame[y1:y2, x1:x2]\n            \n            #-- save coped object --\n            if frame_number % (number_of_frames//5) == 0:\n                file_name = f'frame_{frame_number}_{i}_{label}.png'            \n                cv2.imwrite(video_result_dir_path + file_name, cropped_object)\n            \n            #-- show cropped object --\n            if frame_number % (number_of_frames//5) == 0:\n                plt.figure(figsize=(3, 3))\n                plt.imshow(cropped_object)\n                plt.axis('off')\n                plt.title(label)\n                plt.show\n            \n            #-- plot bbox on the frame --\n            if 'yolov8' in label:\n                color = (255, 0, 0)\n            elif 'yolo_world' in label:\n                color = (0, 255, 0)\n            elif 'dino' in label:\n                color = (0, 0, 255)\n                \n            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)  #-- Red box with thickness 2 --               \n            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n            \n            \n            \n        #-- Add frame to result video --\n        result_video.write(frame)\n\n        #-- show some frames --\n        if frame_number % (number_of_frames//5) == 0:\n            plt.figure(figsize=(10, 10))\n            plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n            plt.axis('off')\n            plt.title(f'moving objcs - frame number={frame_number}')\n            file_name = f'moving_objcs_{frame_number}.png'\n            plt.savefig(video_result_dir_path + file_name)\n            plt.show()   \n    \n        \n        \n    #-- zip results --\n    shutil.make_archive(out_path+video_result_dir_name, 'zip', video_result_dir_path)    \n\n    #-- release videos --\n    video.release()\n    result_video.release()    \n    \n    \n\n\n#-- remove folders --\nshutil.rmtree(result_video_dir)\ndisplay.clear_output()   \nprint(':)')\n#-----------------------------------------------------------------------------------------------------------------    ","metadata":{"execution":{"iopub.status.busy":"2024-06-25T08:43:53.436052Z","iopub.execute_input":"2024-06-25T08:43:53.436460Z","iopub.status.idle":"2024-06-25T08:48:00.067470Z","shell.execute_reply.started":"2024-06-25T08:43:53.436427Z","shell.execute_reply":"2024-06-25T08:48:00.066424Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":":)\n","output_type":"stream"}]}]}